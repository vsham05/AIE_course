# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 8)
- Признаки: все числовые (`f01`–`f08`)
- Пропуски: нет
- "Подлости" датасета: признаки в сильно разных шкалах, наличие шумовых признаков

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 32)
- Признаки: 30 числовых (`n01`–`n30`) + 2 категориальных (`cat_a`, `cat_b`)
- Пропуски: есть (~1.7–2.1% в числовых признаках)
- "Подлости" датасета: высокая размерность, пропуски в числовых признаках, наличие категориальных признаков

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000, 32)
- Признаки: 30 числовых (`n01`–`n30`) + 2 категориальных (`cat_a`, `cat_b`)
- Пропуски: есть (~1.7–2.2% в числовых признаках)
- "Подлости" датасета: высокая размерность, пропуски в числовых признаках, наличие категориальных признаков

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: числовые признаки масштабировались с помощью `StandardScaler`, пропуски заполнялись медианой (`SimpleImputer(strategy="median")`), категориальные признаки обрабатывались через `SimpleImputer(strategy="most_frequent")` и `OneHotEncoder(handle_unknown="ignore")`; PCA использовался только для визуализации
- Поиск гиперпараметров:
  - KMeans: `k` от 2 до 10, фиксированные `random_state=42`, `n_init=10`
  - DBSCAN: `eps` от 0.3 до 2.0 (10 значений), `min_samples` ∈ {3, 5, 10}
  - выбор "лучшего" решения осуществлялся по максимальному значению `silhouette_score` с учётом интерпретируемости
- Метрики: для KMeans метрики считались по всем точкам; для DBSCAN — только по non-noise точках (где `label != -1`)
- Визуализация: PCA(2D) с раскраской по кластерам для лучшего решения на каждом датасете; t-SNE не использовался

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k` от 2 до 10, фиксированы `random_state=42`, `n_init=10`)
- DBSCAN (`eps` и `min_samples` подбирались по сетке; доля шума фиксировалась)

Опционально: третий метод не применялся.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, k=3
- Метрики (silhouette / DB / CH): 0.62 / 0.85 / 1250.3
- Если был DBSCAN: доля шума ~15%, silhouette ниже (0.48)
- Коротко: решение разумно, потому что после масштабирования кластеры стали компактными и сферическими — идеально для KMeans

### 4.2 Dataset B

- Лучший метод и параметры: KMeans, k=4
- Метрики (silhouette / DB / CH): 0.38 / 1.42 / 580.6
- Если был DBSCAN: доля шума >25%, silhouette 0.27
- Коротко: несмотря на высокую размерность и пропуски, препроцессинг позволил KMeans найти устойчивые кластеры; DBSCAN оказался нестабильным из-за высокой размерности

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, k=5
- Метрики (silhouette / DB / CH): 0.41 / 1.35 / 620.7
- Если был DBSCAN: доля шума >30%, silhouette 0.29
- Коротко: препроцессинг корректно обработал пропуски и категориальные признаки; KMeans показал более стабильные результаты по сравнению с DBSCAN

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" только при отсутствии масштабирования, но после корректного препроцессинга работает стабильно даже в высоких размерностях
- DBSCAN проигрывает на dataset-02 и dataset-04 из-за высокой размерности — расстояния становятся менее информативными, что приводит к большому количеству шума
- Сильнее всего на результат повлияло масштабирование — без него KMeans на dataset-01 давал бессмысленные кластеры

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости: 5 запусков KMeans с разными `random_state` на dataset-01 (k=3)
- Средний ARI между парами решений: 0.98 ± 0.01
- Вывод: решение устойчиво, так как KMeans на хорошо разделённых сферических кластерах почти всегда сходится к одному и тому же разбиению

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через анализ средних значений признаков в каждом кластере после обратного преобразования масштаба
- В dataset-02 и dataset-04 кластеры различались по профилям числовых признаков и распределению категориальных переменных
- Например, один кластер характеризовался высокими значениями первых 10 числовых признаков и доминированием категории "A" в `cat_a`

## 6. Conclusion

1. Масштабирование обязательно для distance-based методов кластеризации.
2. KMeans эффективен не только для простых случаев, но и в высоких размерностях при правильном препроцессинге.
3. Внутренние метрики полезны, но должны использоваться совместно с визуализацией и содержательным анализом.
4. Для DBSCAN метрики качества следует рассчитывать только на non-noise точках.
5. Препроцессинг (обработка пропусков, кодирование, масштабирование) — неотъемлемая часть unsupervised pipeline.
6. PCA является надёжным инструментом для двумерной визуализации кластеров.
7. Устойчивость решений необходимо проверять даже в unsupervised-задачах.
8. "Честный" unsupervised-эксперимент требует воспроизводимости, прозрачного выбора гиперпараметров и корректной оценки качества.