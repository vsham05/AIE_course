{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "361ebbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    "    adjusted_rand_score\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Создание папок\n",
    "Path(\"artifacts/figures\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"artifacts/labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Список датасетов\n",
    "DATASET_PATHS = [\n",
    "    \"data/S07-hw-dataset-01.csv\",\n",
    "    \"data/S07-hw-dataset-02.csv\",\n",
    "    \"data/S07-hw-dataset-04.csv\"\n",
    "]\n",
    "\n",
    "all_metrics = {}\n",
    "best_configs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26fa510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_types(df):\n",
    "    cols = [c for c in df.columns if c != \"sample_id\"]\n",
    "    num_cols = df[cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = df[cols].select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "def safe_silhouette(X, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    if len(unique_labels) == 1:\n",
    "        return -1  # неделимый кластер\n",
    "    if -1 in unique_labels and len(unique_labels) == 2:\n",
    "        return -1\n",
    "    mask = labels != -1\n",
    "    if mask.sum() == 0:\n",
    "        return -1\n",
    "    if mask.sum() == 1:\n",
    "        return -1\n",
    "    return silhouette_score(X[mask], labels[mask])\n",
    "\n",
    "def compute_metrics(X, labels, algo_name):\n",
    "    noise_ratio = np.mean(labels == -1) if -1 in labels else 0.0\n",
    "    \n",
    "    if algo_name == \"DBSCAN\":\n",
    "        mask = labels != -1\n",
    "        if mask.sum() < 2:\n",
    "            sil = db = ch = -1\n",
    "        else:\n",
    "            X_clean = X[mask]\n",
    "            labels_clean = labels[mask]\n",
    "            sil = silhouette_score(X_clean, labels_clean) if len(np.unique(labels_clean)) > 1 else -1\n",
    "            db = davies_bouldin_score(X_clean, labels_clean) if len(np.unique(labels_clean)) > 1 else np.inf\n",
    "            ch = calinski_harabasz_score(X_clean, labels_clean) if len(np.unique(labels_clean)) > 1 else -1\n",
    "    else:\n",
    "        sil = silhouette_score(X, labels) if len(np.unique(labels)) > 1 else -1\n",
    "        db = davies_bouldin_score(X, labels) if len(np.unique(labels)) > 1 else np.inf\n",
    "        ch = calinski_harabasz_score(X, labels) if len(np.unique(labels)) > 1 else -1\n",
    "\n",
    "    return {\n",
    "        \"silhouette\": float(sil),\n",
    "        \"davies_bouldin\": float(db),\n",
    "        \"calinski_harabasz\": float(ch),\n",
    "        \"noise_ratio\": float(noise_ratio)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c361a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Обработка: data/S07-hw-dataset-01.csv\n",
      "============================================================\n",
      "Форма: (12000, 8)\n",
      "Пропуски:\n",
      " f01    0.0\n",
      "f02    0.0\n",
      "f03    0.0\n",
      "f04    0.0\n",
      "f05    0.0\n",
      "f06    0.0\n",
      "f07    0.0\n",
      "f08    0.0\n",
      "dtype: float64\n",
      "Числовые признаки: ['f01', 'f02', 'f03', 'f04', 'f05', 'f06', 'f07', 'f08']\n",
      "Категориальные признаки: []\n",
      "\n",
      "После препроцессинга: (12000, 8)\n",
      "\n",
      "============================================================\n",
      "Обработка: data/S07-hw-dataset-02.csv\n",
      "============================================================\n",
      "Форма: (8000, 3)\n",
      "Пропуски:\n",
      " x1         0.0\n",
      "x2         0.0\n",
      "z_noise    0.0\n",
      "dtype: float64\n",
      "Числовые признаки: ['x1', 'x2', 'z_noise']\n",
      "Категориальные признаки: []\n",
      "\n",
      "После препроцессинга: (8000, 3)\n",
      "\n",
      "============================================================\n",
      "Обработка: data/S07-hw-dataset-04.csv\n",
      "============================================================\n",
      "Форма: (10000, 32)\n",
      "Пропуски:\n",
      " cat_a    0.0000\n",
      "cat_b    0.0000\n",
      "n01      0.0174\n",
      "n02      0.0189\n",
      "n03      0.0199\n",
      "n04      0.0192\n",
      "n05      0.0201\n",
      "n06      0.0183\n",
      "n07      0.0204\n",
      "n08      0.0194\n",
      "n09      0.0195\n",
      "n10      0.0189\n",
      "n11      0.0204\n",
      "n12      0.0202\n",
      "n13      0.0197\n",
      "n14      0.0198\n",
      "n15      0.0186\n",
      "n16      0.0191\n",
      "n17      0.0212\n",
      "n18      0.0212\n",
      "n19      0.0187\n",
      "n20      0.0203\n",
      "n21      0.0215\n",
      "n22      0.0196\n",
      "n23      0.0171\n",
      "n24      0.0207\n",
      "n25      0.0185\n",
      "n26      0.0224\n",
      "n27      0.0197\n",
      "n28      0.0211\n",
      "n29      0.0202\n",
      "n30      0.0195\n",
      "dtype: float64\n",
      "Числовые признаки: ['n01', 'n02', 'n03', 'n04', 'n05', 'n06', 'n07', 'n08', 'n09', 'n10', 'n11', 'n12', 'n13', 'n14', 'n15', 'n16', 'n17', 'n18', 'n19', 'n20', 'n21', 'n22', 'n23', 'n24', 'n25', 'n26', 'n27', 'n28', 'n29', 'n30']\n",
      "Категориальные признаки: ['cat_a', 'cat_b']\n",
      "\n",
      "После препроцессинга: (10000, 42)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for ds_path in DATASET_PATHS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Обработка: {ds_path}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    df = pd.read_csv(ds_path)\n",
    "    sample_ids = df[\"sample_id\"].copy()\n",
    "    X_raw = df.drop(columns=[\"sample_id\"])\n",
    "    \n",
    "    print(\"Форма:\", X_raw.shape)\n",
    "    print(\"Пропуски:\\n\", X_raw.isnull().mean())\n",
    "    num_cols, cat_cols = get_column_types(df)\n",
    "    print(\"Числовые признаки:\", num_cols)\n",
    "    print(\"Категориальные признаки:\", cat_cols)\n",
    "    \n",
    "    transformers = []\n",
    "    if num_cols:\n",
    "        num_pipe = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "        transformers.append((\"num\", num_pipe, num_cols))\n",
    "    if cat_cols:\n",
    "        cat_pipe = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ])\n",
    "        transformers.append((\"cat\", cat_pipe, cat_cols))\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers, remainder=\"drop\")\n",
    "    X_processed = preprocessor.fit_transform(X_raw)\n",
    "    print(f\"\\nПосле препроцессинга: {X_processed.shape}\")\n",
    "    \n",
    "    results[ds_path] = {\n",
    "        \"sample_ids\": sample_ids,\n",
    "        \"X_raw\": X_raw,\n",
    "        \"X_processed\": X_processed,\n",
    "        \"num_cols\": num_cols,\n",
    "        \"cat_cols\": cat_cols\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d941350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший метод для S07-hw-dataset-01: {'algo': 'KMeans', 'params': {'k': 2}}\n",
      "Лучший метод для S07-hw-dataset-02: {'algo': 'DBSCAN', 'params': {'eps': np.float64(0.6777777777777778), 'min_samples': 3}}\n",
      "Лучший метод для S07-hw-dataset-04: {'algo': 'DBSCAN', 'params': {'eps': np.float64(1.6222222222222222), 'min_samples': 10}}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "metrics_summary = {}\n",
    "best_configs = {}\n",
    "\n",
    "for ds_path in DATASET_PATHS:\n",
    "    \n",
    "    X = results[ds_path][\"X_processed\"]\n",
    "    sample_ids = results[ds_path][\"sample_ids\"]\n",
    "    ds_name = Path(ds_path).stem  \n",
    "    \n",
    "    metrics_summary[ds_name] = {}\n",
    "    best_score = -np.inf\n",
    "    best_model_info = None\n",
    "    best_labels = None\n",
    "    \n",
    "    k_range = range(2, 11)\n",
    "    sil_scores_kmeans = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        sil = silhouette_score(X, labels)\n",
    "        sil_scores_kmeans.append(sil)\n",
    "        \n",
    "        metrics = compute_metrics(X, labels, \"KMeans\")\n",
    "        metrics_summary[ds_name][f\"KMeans_k{k}\"] = metrics\n",
    "        \n",
    "        if sil > best_score:\n",
    "            best_score = sil\n",
    "            best_model_info = {\"algo\": \"KMeans\", \"params\": {\"k\": k}}\n",
    "            best_labels = labels.copy()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(k_range, sil_scores_kmeans, marker='o')\n",
    "    plt.title(f\"{ds_name}: Silhouette vs k (KMeans)\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.savefig(f\"artifacts/figures/sil_kmeans_{ds_name}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    eps_vals = np.linspace(0.3, 2.0, 10)\n",
    "    min_samples_vals = [3, 5, 10]\n",
    "    \n",
    "    best_sil_dbscan = -1\n",
    "    best_dbscan_params = None\n",
    "    best_dbscan_labels = None\n",
    "    \n",
    "    for eps, min_samples in product(eps_vals, min_samples_vals):\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(X)\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        if n_clusters < 2:\n",
    "            continue\n",
    "        sil = safe_silhouette(X, labels)\n",
    "        if sil > best_sil_dbscan:\n",
    "            best_sil_dbscan = sil\n",
    "            best_dbscan_params = {\"eps\": eps, \"min_samples\": min_samples}\n",
    "            best_dbscan_labels = labels.copy()\n",
    "    \n",
    "    if best_dbscan_params is not None:\n",
    "        metrics = compute_metrics(X, best_dbscan_labels, \"DBSCAN\")\n",
    "        model_key = f\"DBSCAN_eps{best_dbscan_params['eps']:.2f}_ms{best_dbscan_params['min_samples']}\"\n",
    "        metrics_summary[ds_name][model_key] = metrics\n",
    "        \n",
    "        if best_sil_dbscan > best_score:\n",
    "            best_score = best_sil_dbscan\n",
    "            best_model_info = {\"algo\": \"DBSCAN\", \"params\": best_dbscan_params}\n",
    "            best_labels = best_dbscan_labels.copy()\n",
    "    \n",
    "    sil_vs_eps = []\n",
    "    for eps in eps_vals:\n",
    "        labels = DBSCAN(eps=eps, min_samples=5).fit_predict(X)\n",
    "        sil = safe_silhouette(X, labels)\n",
    "        sil_vs_eps.append(sil)\n",
    "    plt.figure()\n",
    "    plt.plot(eps_vals, sil_vs_eps, marker='o')\n",
    "    plt.title(f\"{ds_name}: Silhouette vs eps (DBSCAN, min_samples=5)\")\n",
    "    plt.xlabel(\"eps\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.savefig(f\"artifacts/figures/sil_dbscan_{ds_name}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    output_df = pd.DataFrame({\n",
    "        \"sample_id\": sample_ids,\n",
    "        \"cluster_label\": best_labels\n",
    "    })\n",
    "    output_df.to_csv(f\"artifacts/labels/labels_hw07_{ds_name.split('-')[-1]}.csv\", index=False)\n",
    "    \n",
    "    best_configs[ds_name] = best_model_info\n",
    "    print(f\"Лучший метод для {ds_name}: {best_model_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cabea62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_path in DATASET_PATHS:\n",
    "    ds_name = Path(ds_path).stem\n",
    "    X = results[ds_path][\"X_processed\"]\n",
    "    sample_ids = results[ds_path][\"sample_ids\"]\n",
    "    \n",
    "    label_file = f\"artifacts/labels/labels_hw07_{ds_name.split('-')[-1]}.csv\"\n",
    "    labels_df = pd.read_csv(label_file)\n",
    "    labels = labels_df[\"cluster_label\"].values\n",
    "    \n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    plt.figure()\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"tab10\", s=10)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(f\"{ds_name}: PCA (лучшая кластеризация)\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.savefig(f\"artifacts/figures/pca_{ds_name}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37f7edb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний ARI: 1.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "ds_path = DATASET_PATHS[0]  \n",
    "ds_name = Path(ds_path).stem\n",
    "X = results[ds_path][\"X_processed\"]\n",
    "\n",
    "ari_scores = []\n",
    "labels_list = []\n",
    "\n",
    "for seed in range(5):\n",
    "    kmeans = KMeans(n_clusters=best_configs[ds_name][\"params\"][\"k\"], random_state=seed, n_init=10)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    labels_list.append(labels)\n",
    "\n",
    "for i in range(len(labels_list)):\n",
    "    for j in range(i+1, len(labels_list)):\n",
    "        ari = adjusted_rand_score(labels_list[i], labels_list[j])\n",
    "        ari_scores.append(ari)\n",
    "\n",
    "print(f\"Средний ARI: {np.mean(ari_scores):.4f} ± {np.std(ari_scores):.4f}\")\n",
    "\n",
    "with open(\"artifacts/stability_ari.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"dataset\": ds_name,\n",
    "        \"ari_scores\": [float(x) for x in ari_scores],\n",
    "        \"mean_ari\": float(np.mean(ari_scores)),\n",
    "        \"std_ari\": float(np.std(ari_scores))\n",
    "    }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "370c7bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics = {}\n",
    "for ds_path, metrics in metrics_summary.items():\n",
    "    final_metrics[ds_path] = metrics\n",
    "\n",
    "with open(\"artifacts/metrics_summary.json\", \"w\") as f:\n",
    "    json.dump(final_metrics, f, indent=2)\n",
    "\n",
    "with open(\"artifacts/best_configs.json\", \"w\") as f:\n",
    "    json.dump(best_configs, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
