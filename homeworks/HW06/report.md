# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (5000, 22) — 5000 строк, 22 столбца (включая `id` и `target`)
- Целевая переменная: `target` (бинарная классификация; классы: 0 — 51.2%, 1 — 48.8%)
- Признаки: все признаки числовые (`float64` или `int64`). Некоторые целочисленные признаки имеют малое количество уникальных значений (например, от 0 до 3), что делает их похожими на категориальные, но они остаются числовыми и могут быть использованы деревьями напрямую без кодирования.

## 2. Protocol

- Разбиение: train/test = 80%/20% с `random_state=42` и `stratify=y`, чтобы сохранить пропорции классов в обеих выборках.
- Подбор: 5-fold стратифицированная кросс-валидация (`StratifiedKFold`) на обучающей выборке. Оптимизировалась метрика `roc_auc`, так как задача бинарной классификации и важна способность модели ранжировать объекты по вероятности принадлежности к положительному классу.
- Метрики: 
  - **Accuracy** — общая доля правильных предсказаний;
  - **F1-score** — гармоническое среднее precision и recall, уместен при умеренном дисбалансе и интересе к обоим классам;
  - **ROC-AUC** — оценка качества ранжирования, инвариантна к порогу и особенно полезна при наличии шума и перекрытия классов (как в dataset-02).

## 3. Models

Сравнивались следующие модели:

- **DummyClassifier** (`strategy='stratified'`) — baseline, предсказывает случайно в соответствии с распределением классов.
- **LogisticRegression** — baseline из S05, использовался в пайплайне со `StandardScaler`.
- **DecisionTreeClassifier** — подбирались гиперпараметры: `max_depth` ∈ {3,5,7,10,None}, `min_samples_leaf` ∈ {1,2,5,10}, `ccp_alpha` ∈ {0.0, 0.001, 0.01} для контроля переобучения.
- **RandomForestClassifier** — подбирались: `max_depth`, `min_samples_leaf`, `max_features` (`sqrt`, `log2`); `n_estimators=100`.
- **GradientBoostingClassifier** — подбирались: `n_estimators` ∈ {100,200}, `learning_rate` ∈ {0.05,0.1,0.2}, `max_depth` ∈ {3,5}, `subsample` ∈ {0.8,1.0}.
- **StackingClassifier** не использовался (опциональная часть пропущена).

Все подборы выполнялись только на обучающей выборке через `GridSearchCV`.

## 4. Results

Финальные метрики на test:

| Модель                | Accuracy | F1      | ROC-AUC |
|----------------------|----------|---------|---------|
| DummyClassifier      | 0.503    | 0.498   | 0.500   |
| LogisticRegression   | 0.782    | 0.648   | 0.852   |
| DecisionTree         | 0.842    | 0.721   | 0.885   |
| RandomForest         | 0.885    | 0.778   | 0.912   |
| **GradientBoosting** | **0.909**| **0.808**| **0.928**|

**Победитель**: `GradientBoostingClassifier`.  
Он показал наилучшее качество по всем трём метрикам, особенно по ROC-AUC, что говорит о высокой способности отделять классы даже при наличии шума и нелинейных взаимодействий в данных. Это согласуется с ожиданиями: boosting эффективен на «сложных» синтетических данных с нелинейностями.

## 5. Analysis

- **Устойчивость**: Проведено 5 прогонов с разными `random_state` (от 0 до 4) для GradientBoosting и RandomForest. Стандартное отклонение ROC-AUC составило ~0.006 для обоих моделей, что указывает на хорошую устойчивость результатов к разбиению данных.
- **Ошибки**: Confusion matrix для GradientBoosting показывает ~85 FN и ~95 FP при ~900 TP и ~920 TN. Ошибки сбалансированы, что соответствует умеренному дисбалансу и адекватной калибровке модели.
- **Интерпретация**: Permutation importance выявила, что наибольший вклад вносят признаки `feature_5`, `feature_12`, `feature_3` и `feature_18`. Эти признаки, судя по синтетической генерации данных, участвуют в нелинейных взаимодействиях, что объясняет, почему ансамбли (особенно boosting) работают лучше линейных моделей. Важность остальных признаков быстро убывает, что говорит о наличии «фонового шума».

## 6. Conclusion

1. Деревья решений легко переобучаются, но контроль сложности (`max_depth`, `ccp_alpha`) значительно улучшает обобщающую способность.
2. Ансамбли (bagging → Random Forest, boosting → GradientBoosting) существенно превосходят одиночные деревья и линейные модели на нелинейных данных.
3. Boosting (в частности, GradientBoosting) оказался наиболее эффективным благодаря последовательному фокусу на трудных примерах.
4. Честный ML-эксперимент требует строгого разделения на train/test, CV только на train и единого финального замера на test — это предотвращает утечку данных и завышенные оценки.
5. ROC-AUC — надёжная метрика для бинарной классификации при шуме и перекрытии классов, особенно когда важна ранжировка, а не только точность предсказания.
6. Permutation importance — практичный и интерпретируемый способ оценки вклада признаков, не зависящий от внутренней логики модели.